{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml\n",
    "with open(\"mongo_config.yaml\", \"r\") as infile:\n",
    "    pars = yaml.safe_load(infile)['PC_PP']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clean References and Mesh terms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Coocurence matrices yearly\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import * \n",
    "\n",
    "test = create_cooc(client_name = pars['client_name'],\n",
    "                   db_name = \"Pubmed\",\n",
    "                   collection_name = \"articles\",\n",
    "                   year_var=\"Journal_JournalIssue_PubDate_Year\",\n",
    "                   month=False, var = \"CR_year_category\",\n",
    "                   sub_var = \"journal\",\n",
    "                   weighted_network = True,self_loop = True)\n",
    "\n",
    "test.main()\n",
    "test = create_cooc(client_name = pars['client_name'],\n",
    "                   db_name = \"Pubmed\",\n",
    "                   collection_name = \"articles\", \n",
    "                   year_var=\"Journal_JournalIssue_PubDate_Year\",\n",
    "                   month=False, var = \"CR_year_category\",\n",
    "                   sub_var = \"journal\",\n",
    "                   weighted_network = False,self_loop = False)\n",
    "\n",
    "test.main()\n",
    "test = create_cooc(client_name = pars['client_name'],\n",
    "                   db_name = \"Pubmed\",\n",
    "                   collection_name = \"articles\", \n",
    "                   year_var=\"Journal_JournalIssue_PubDate_Year\",\n",
    "                   month=False, var = \"Mesh_year_categoy\",\n",
    "                   sub_var = \"descUI\",\n",
    "                   weighted_network = False, self_loop = False)\n",
    "\n",
    "test.main()\n",
    "test = create_cooc(client_name = pars['client_name'],\n",
    "                   db_name = \"Pubmed\",\n",
    "                   collection_name = \"articles\", \n",
    "                   year_var=\"Journal_JournalIssue_PubDate_Year\",\n",
    "                   month=False, \n",
    "                   var = \"Mesh_year_categoy\",\n",
    "                   sub_var = \"descUI\",\n",
    "                   weighted_network = True, self_loop = True)\n",
    "\n",
    "test.main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Indicators\n",
    "\n",
    "You basically have the choice between using mongo or using a list of dict yearly.\n",
    "To use mongo, just feed the Dataset class with a client_name, otherwise it will look for a pickle file for the given year."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cited References Journals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from indicators.utils import *\n",
    "focal_year = 2000\n",
    "\n",
    "data = Dataset(client_name = pars['client_name'], \n",
    "               db_name =  pars['db_name'],\n",
    "               collection_name = pars['pkg']['collection_name'],\n",
    "               var = pars['pkg']['j_ref']['var'],\n",
    "               sub_var = pars['pkg']['j_ref']['sub_var'],\n",
    "               focal_year = focal_year)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Atypicality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from indicators.atypicality import *\n",
    "\n",
    "data.get_items(indicator = 'atypicality')\n",
    "\n",
    "atypicality = Atypicality(data.VAR,\n",
    "                          focal_year = focal_year,\n",
    "                          current_items = data.current_items,\n",
    "                          unique_items = data.unique_items,\n",
    "                          true_current_adj_freq = data.current_adj)\n",
    "\n",
    "atypicality.sample_network(nb_sample = 20)\n",
    "atypicality.compute_comb_score()\n",
    "\n",
    "data.update_paper_values(indicator = 'atypicality',\n",
    "                         tomongo = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Commonness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from indicators.commonness import *\n",
    "\n",
    "data.get_items(indicator = 'commonness')\n",
    "\n",
    "commonness = Commonness(var = data.VAR,\n",
    "                        focal_year = focal_year,\n",
    "                        current_adj = data.current_adj)\n",
    "\n",
    "commonness.compute_comb_score()\n",
    "\n",
    "data.update_paper_values(indicator = 'commonness',\n",
    "                        tomongo = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Novelty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from indicators.novelty import *\n",
    "\n",
    "data.get_items(indicator = 'novelty')\n",
    "\n",
    "novelty = Novelty(var = data.VAR,\n",
    "                  focal_year = focal_year,\n",
    "                  time_window = 3,\n",
    "                  n_reutilisation = 1)\n",
    "\n",
    "novelty.get_matrices_sums()\n",
    "novelty.compute_comb_score()\n",
    "\n",
    "data.update_paper_values(indicator = 'novelty',\n",
    "                         tomongo=True,\n",
    "                         time_window = 3,\n",
    "                         n_reutilisation = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Our Indicator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mesh terms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from indicators.utils import *\n",
    "focal_year = 2000\n",
    "\n",
    "data = Dataset(client_name = pars['client_name'], \n",
    "               db_name =  pars['db_name'],\n",
    "               collection_name = pars['pkg']['collection_name'],\n",
    "               var = pars['pkg']['mesh']['var'],\n",
    "               sub_var = pars['pkg']['mesh']['sub_var'],\n",
    "               focal_year = focal_year)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Atypicality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'Data/Journal_JournalIssue_PubDate_Year/Mesh_year_categoy/weighted_network_self_loop/name2index.p'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-efb4aaf93d63>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mindicators\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0matypicality\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_items\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindicator\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'atypicality'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m atypicality = Atypicality(data.VAR,\n",
      "\u001b[0;32m~/Documents/GitHub/Taxonomy-of-novelty/newpackage/indicators/utils.py\u001b[0m in \u001b[0;36mget_items\u001b[0;34m(self, indicator, restrict_wos_journal)\u001b[0m\n\u001b[1;32m    254\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    255\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mindicator\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'atypicality'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'novelty'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'commonness'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 256\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchoose_path\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindicator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    257\u001b[0m             self.current_adj =  pickle.load(\n\u001b[1;32m    258\u001b[0m                 open(self.path+'/{}.p'.format(self.focal_year),\n",
      "\u001b[0;32m~/Documents/GitHub/Taxonomy-of-novelty/newpackage/indicators/utils.py\u001b[0m in \u001b[0;36mchoose_path\u001b[0;34m(self, indicator)\u001b[0m\n\u001b[1;32m    213\u001b[0m         \u001b[0mtype2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'no_self_loop'\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mindicator\u001b[0m \u001b[0;32min\u001b[0m \u001b[0munw\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m'self_loop'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    214\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"Data/{}/{}/{}_{}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mVAR_YEAR\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mVAR\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtype1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtype2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 215\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique_items\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\"/name2index.p\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"rb\"\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    216\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    217\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'Data/Journal_JournalIssue_PubDate_Year/Mesh_year_categoy/weighted_network_self_loop/name2index.p'"
     ]
    }
   ],
   "source": [
    "from indicators.atypicality import *\n",
    "\n",
    "data.get_items(indicator = 'atypicality')\n",
    "\n",
    "atypicality = Atypicality(data.VAR,\n",
    "                          focal_year = focal_year,\n",
    "                          current_items = data.current_items,\n",
    "                          unique_items = data.unique_items,\n",
    "                          true_current_adj_freq = data.current_adj)\n",
    "\n",
    "atypicality.sample_network(nb_sample = 20)\n",
    "atypicality.compute_comb_score()\n",
    "\n",
    "data.update_paper_values(indicator = 'atypicality',\n",
    "                         tomongo = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Commonness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from indicators.commonness import *\n",
    "\n",
    "data.get_items(indicator = 'commonness')\n",
    "\n",
    "commonness = Commonness(var = data.VAR,\n",
    "                        focal_year = focal_year,\n",
    "                        current_adj = data.current_adj)\n",
    "\n",
    "commonness.compute_comb_score()\n",
    "\n",
    "data.update_paper_values(indicator = 'commonness',\n",
    "                        tomongo = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Novelty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from indicators.novelty import *\n",
    "\n",
    "data.get_items(indicator = 'novelty')\n",
    "\n",
    "novelty = Novelty(var = data.VAR,\n",
    "                  focal_year = focal_year,\n",
    "                  time_window = 3,\n",
    "                  n_reutilisation = 1)\n",
    "\n",
    "novelty.get_matrices_sums()\n",
    "novelty.compute_comb_score()\n",
    "\n",
    "data.update_paper_values(indicator = 'novelty',\n",
    "                         tomongo=True,\n",
    "                         time_window = 3,\n",
    "                         n_reutilisation = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Our Indicator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cited References PMID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "__init__() missing 2 required positional arguments: 'var_id' and 'var_year'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-8c4153488c22>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m                \u001b[0mcollection_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpars\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'pkg'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'collection_name'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m                \u001b[0mvar\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'refs_pmids'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m                focal_year = focal_year)\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: __init__() missing 2 required positional arguments: 'var_id' and 'var_year'"
     ]
    }
   ],
   "source": [
    "from novelpy import Dataset\n",
    "focal_year = 2000\n",
    "\n",
    "data = Dataset(client_name = pars['client_name'], \n",
    "               db_name =  pars['db_name'],\n",
    "               collection_name = pars['pkg']['collection_name'],\n",
    "               var = 'refs_pmids',\n",
    "               focal_year = focal_year)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Disruptiveness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "367417it [00:12, 29865.65it/s]\n"
     ]
    }
   ],
   "source": [
    "from novelpy import Disruptiveness, Dataset\n",
    "from joblib import Parallel, delayed\n",
    "import tqdm\n",
    "\n",
    "data = Dataset(var = 'refs_pmid_wos',\n",
    "                       var_id = 'PMID',\n",
    "                       focal_year = 2000,\n",
    "                       var_year = 'Journal_JournalIssue_PubDate_Year',\n",
    "                       client_name = pars['client_name'], \n",
    "                       db_name =  pars['db_name'],\n",
    "                       collection_name = 'citation_data')\n",
    "data.get_items(indicator = 'distruptiveness')\n",
    "\n",
    "disruptiveness = Disruptiveness(focal_year = 2000,\n",
    "                                var_id = 'PMID',\n",
    "                                var_refs_list ='refs_pmid_wos',\n",
    "                                var_year = 'Journal_JournalIssue_PubDate_Year')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/367417 [00:00<?, ?it/s]\u001b[A\n",
      "  0%|          | 8/367417 [00:00<1:24:30, 72.46it/s]\u001b[A\n",
      "  0%|          | 8/367417 [00:16<1:24:30, 72.46it/s]\u001b[A\n",
      "  0%|          | 16/367417 [00:47<182:32:01,  1.79s/it]\u001b[A"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-75f5696980bc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0mcollection_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'citation_data'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m         collection2update = 'citation_data') \n\u001b[0;32m---> 10\u001b[0;31m     for idx in tqdm.tqdm(list(data.current_items)))\n\u001b[0m",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1052\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieval_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1054\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1055\u001b[0m             \u001b[0;31m# Make sure that we get a last message telling us we are done\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1056\u001b[0m             \u001b[0melapsed_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_start_time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36mretrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    931\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    932\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'supports_timeout'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 933\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    934\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    935\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mwrap_future_result\u001b[0;34m(future, timeout)\u001b[0m\n\u001b[1;32m    540\u001b[0m         AsyncResults.get from multiprocessing.\"\"\"\n\u001b[1;32m    541\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 542\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfuture\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    543\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mCfTimeoutError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    544\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.6/concurrent/futures/_base.py\u001b[0m in \u001b[0;36mresult\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    425\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__get_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    426\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 427\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_condition\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    428\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    429\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_state\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mCANCELLED\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCANCELLED_AND_NOTIFIED\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.6/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    293\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m    \u001b[0;31m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    294\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 295\u001b[0;31m                 \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    296\u001b[0m                 \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    297\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "Parallel(n_jobs=8)(\n",
    "    delayed(disruptiveness.compute_scores)(\n",
    "        focal_paper_id = idx,\n",
    "        focal_paper_refs = data.current_items[idx],\n",
    "        tomongo = True,\n",
    "        client_name = pars['client_name'], \n",
    "        db_name = pars['db_name'],\n",
    "        collection_name = 'citation_data',\n",
    "        collection2update = 'citation_data') \n",
    "    for idx in tqdm.tqdm(list(data.current_items)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": false,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
