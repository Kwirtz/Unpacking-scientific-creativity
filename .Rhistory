draw_plot(figc, x=2/3, y=1.75/3, width=1/3, height=1.5/3)+
draw_image(img, x=0, y=0, width=1/2, height=1.25/3)+
draw_image(img, x=1/2, y=0, width=1/2, height=1.25/3)+
draw_plot_label(label=c("A","B", "C", "D","E"),x=c(0, 1/3, 2/3, 0, 1/2),y=c(0.99, 0.99, 0.99, 1/3,1/3),
size = 10)
fig1
fig1 = ggdraw() +
draw_plot(figa, x=0, y=1.75/3, width=1/3, height=1.4/3)+
draw_plot(figb, x=1/3, y=1.75/3, width=1/3, height=1.4/3)+
draw_plot(figc, x=2/3, y=1.75/3, width=1/3, height=1.4/3)+
draw_image(img, x=0, y=0, width=1/2, height=1.25/3)+
draw_image(img, x=1/2, y=0, width=1/2, height=1.25/3)+
draw_plot_label(label=c("A","B", "C", "D","E"),x=c(0, 1/3, 2/3, 0, 1/2),y=c(0.99, 0.99, 0.99, 1/3,1/3),
size = 10)
fig1
knitr::opts_chunk$set(echo = TRUE)
library(forecast)
library(tseries)
library(TSA)
library(astsa)
library(spectral.methods)
install.packages("C:/Users/kevin/Downloads/spectral.methods_0.7.2.133.tar.gz", repos = NULL, type = "source")
install.packages("C:/Users/kevin/Downloads/spectral.methods_0.7.2.133.tar.gz", repos = NULL, type = "source")
install.packages("Rssa")
install.packages("raster")
install.packages("RNetCDF")
install.packages("ncdf.tools")
c(1:39)
for(i in c(1980:2020)){"gebjahre"+str(i)}
indeed <- "https://www.indeed.com"
result <- paste0(indeed, unlist(c(1980:2020)))
result
result <- paste0("gebjahr_", unlist(c(1980:2020)))
result
result
list(result)
View(list(result))
result <- paste0("gebjahr_", list(c(1980:2020)))
result
result <- paste0("gebjahr_", unlist(c(1980:2020)))
result
type(list)
class(list)
View(result)
list = test
test = list
test = list()
for (i in result){print(i)}
result <- paste0("gebjahr_", unlist(c(1980:2020)))
for (i in result){append(list,i)}
list
test = list()
result <- paste0("gebjahr_", unlist(c(1980:2020)))
for (i in result){append(test,i)}
View(test)
for (i in result){test <- append(test,i)}
View(test)
View(test)
## Read data
getwd()
```{r}
data <- read_csv('../../input/works.csv') %>%
mutate(id = id %>% as.character()) %>%
select(-title, -issn)
```
# Knitr options
### Generic preamble
rm(list = ls(all.names = TRUE)) #will clear all objects includes hidden objects.
gc() #free up memrory and report the memory usage.
graphics.off()
Sys.setenv(LANG = "en") # For english language
options(scipen = 5) # To deactivate annoying scientific number notation
### Load packages
library(tidyverse) # Collection of all the good stuff like dplyr, ggplot2 ect.
data <- read_csv('Data/works.csv') %>%
mutate(id = id %>% as.character()) %>%
select(-title, -issn)
```{r setup, include=FALSE}
# Knitr options
### Generic preamble
rm(list = ls(all.names = TRUE)) #will clear all objects includes hidden objects.
gc() #free up memrory and report the memory usage.
graphics.off()
Sys.setenv(LANG = "en") # For english language
options(scipen = 5) # To deactivate annoying scientific number notation
### Load packages
library(tidyverse) # Collection of all the good stuff like dplyr, ggplot2 ect.
setwd('G:/Github/ai_research')
data <- read_csv('Data/works.csv') %>%
mutate(id = id %>% as.character()) %>%
select(-title, -issn)
### Load packages
setwd('G:/Github/ai_research')
library(tidyverse) # Collection of all the good stuff like dplyr, ggplot2 ect.
library(magrittr) # For extra-piping operators (eg. %<>%)
library(dplyr)
data <- read_csv('Data/works.csv') %>%
mutate(id = id %>% as.character()) %>%
select(-title, -issn)
data <- read_csv('Data/works.csv') %>%
mutate(id = id %>% as.character()) %>%
select(-title, -issn)
### Generic preamble
rm(list = ls(all.names = TRUE)) #will clear all objects includes hidden objects.
gc() #free up memrory and report the memory usage.
graphics.off()
Sys.setenv(LANG = "en") # For english language
options(scipen = 5) # To deactivate annoying scientific number notation
### Load packages
setwd('G:/Github/ai_research')
library(tidyverse) # Collection of all the good stuff like dplyr, ggplot2 ect.
### Load packages
library(tidyverse) # Collection of all the good stuff like dplyr, ggplot2 ect.
install.packages("rlang")
install.packages("rlang")
install.packages("rlang")
install.packages("rlang")
# Knitr options
### Generic preamble
rm(list = ls(all.names = TRUE)) #will clear all objects includes hidden objects.
gc() #free up memrory and report the memory usage.
graphics.off()
Sys.setenv(LANG = "en") # For english language
options(scipen = 5) # To deactivate annoying scientific number notation
### Load packages
library(tidyverse) # Collection of all the good stuff like dplyr, ggplot2 ect.
library(magrittr) # For extra-piping operators (eg. %<>%)
# Descriptives
#library(skimr)
library(stargazer)
library(corrplot)
# ML
library(xgboost)
library(caret)
setwd("G:/Github/Taxonomy-of-novelty")
df <- read_csv("Data/regression.csv")
df$year <- as.factor(df$year)
summary(df)
unique(df$main_category)
novelty_cat <- c("Interesting Hypothesis","New Finding", "Novel Drug Target", "Technical Advance")
variables <- c("nb_ref","year","nb_aut","journal_SJR","is_review","journal_age")
indicators <- c("uzzi_ref","uzzi_mesh","lee_ref","lee_mesh","foster_ref","foster_mesh","wang_ref","wang_mesh","shibayama_abstract","shibayama_title","author_intra_abstract","author_inter_abstract",
"author_intra_title", "author_inter_title")
dependant <-  c("nb_cit","DI1","DI5","DI1nok","DeIn","Breadth","Depth","novel_f1000")
df <- df %>% mutate(novel_f1000 = ifelse(main_category %in% novelty_cat, 1, 0))
df_f1000 <- df %>%
drop_na(main_category)
df_f1000 %>% count(year) %>%
ggplot(aes(x = year, y = n)) +
geom_col() +
theme_classic() +
ggtitle("Number of papers matched with F1000 2000-2005") +
theme(plot.title = element_text(hjust = 0.5))
for (i in unique(df_f1000$main_category)){
df_f1000[paste(i)] <- lengths(regmatches(df_f1000$categories, gregexpr(i,df_f1000$categories)))
}
names(df_f1000) <- str_replace_all(names(df_f1000), c(" " = "_"  ))
summary(df_f1000)
# Simple correlation
df_indicators = df[,append(indicators,dependant)] %>% drop_na()
df_indicators.cor = cor(df_indicators)
corrplot(df_indicators.cor)
# Logit ####
indicator = "wang_ref"
j = 0
for (i in unique(df_f1000$main_category)){
j <- j + 1
name_col = str_replace_all(i, c(" " = "_"  ))
nam <- paste("mod", j, sep = "_")
print(name_col)
df_temp <- df_f1000[,c(variables,c(name_col),c(paste(indicator)))] %>% drop_na()
df_temp[name_col] <- as.factor(as.matrix(df_temp[name_col]))
assign(nam, glm(substitute(i ~ ., list(i = as.name(name_col))),  data = df_temp, family ="binomial"))
}
underscore <- capture.output(
stargazer(mod_1,mod_2,mod_3,mod_4,mod_5,mod_6,mod_7,mod_8,mod_9,mod_10,mod_11,
keep.stat = c("n", "rsq"),
keep = c('nb_ref','nb_aut','journal_SJR','is_review','journal_age'),
out=paste("Result/Regression/mod_", indicator,".tex")))
for (indicator in indicators){
j = 0
for (i in unique(df_f1000$main_category)){
j <- j + 1
name_col = str_replace_all(i, c(" " = "_"  ))
nam <- paste("mod", j, sep = "_")
print(name_col)
df_temp <- df_f1000[,c(variables,c(name_col),c(paste(indicator)))] %>% drop_na()
df_temp[name_col] <- as.factor(as.matrix(df_temp[name_col]))
assign(nam, glm(substitute(i ~ ., list(i = as.name(name_col))),  data = df_temp, family ="binomial"))
}
underscore <- capture.output(
stargazer(mod_1,mod_2,mod_3,mod_4,mod_5,mod_6,mod_7,mod_8,mod_9,mod_10,mod_11,
keep.stat = c("n", "rsq"),
keep = c('nb_ref','nb_aut','journal_SJR','is_review','journal_age'),
out=paste("Result/Regression/mod_", indicator,".tex")))
}
for (indicator in indicators){
j = 0
for (i in unique(df_f1000$main_category)){
j <- j + 1
name_col = str_replace_all(i, c(" " = "_"  ))
nam <- paste("mod", j, sep = "_")
print(name_col)
df_temp <- df_f1000[,c(variables,c(name_col),c(paste(indicator)))] %>% drop_na()
df_temp[name_col] <- as.factor(as.matrix(df_temp[name_col]))
assign(nam, glm(substitute(i ~ ., list(i = as.name(name_col))),  data = df_temp, family ="binomial"))
}
underscore <- capture.output(
stargazer(mod_1,mod_2,mod_3,mod_4,mod_5,mod_6,mod_7,mod_8,mod_9,mod_10,mod_11,
keep.stat = c("n", "rsq"),
keep = c('nb_ref','nb_aut','journal_SJR','is_review','journal_age'),
out=paste("Result/Regression/logit_", indicator,".tex")))
}
append(variables,indicators,)
parts = createDataPartition(df_f1000[,], p = 0.8, list = F)
parts = createDataPartition(df_f1000$novel_f1000, p = 0.8, list = F)
train = df_f1000[parts, ]
test = df_f1000[-parts, ]
novelty_cat
parts = createDataPartition(df_f1000$novel_f1000, p = 0.8, list = F)
train = df_f1000[parts, ]
test = df_f1000[-parts, ]
for(i in indicators){
X_names <- append(c("nb_ref","year","nb_aut","journal_SJR"),c(i))
X_train = data.matrix(train[,X_names])
y_train = data.matrix(train[,"novel_f1000"])
X_test = data.matrix(test[,X_names])
y_test = data.matrix(test[,"novel_f1000"])
# convert the train and test data into xgboost matrix type.
xgboost_train = xgb.DMatrix(data=X_train, label=y_train)
xgboost_test = xgb.DMatrix(data=X_test, label=y_test)
model <- xgboost(data = xgboost_train,                    # the data
max.depth=3,                        # max depth
nrounds=50)                              # max number of boosting iterations
summary(model)
pred_test = predict(model, xgboost_test)
pred_test
pred_test[(pred_test>=0.75)] = 1
pred_test[(pred_test<0.75)] = 0
conf_mat = confusionMatrix(as.factor(y_test), as.factor(pred_test))
print(paste(i,conf_mat$overall))
}
levels(y_test)
print(paste(i,conf_mat$overall))
conf_mat
precision <- conf_mat$byClass['Pos Pred Value']
recall <- conf_mat$byClass['Sensitivity']
accuracy <- conf_mat$byClass['Accuracy']
conf_mat$byClass
accuracy <- conf_mat$overall['Accuracy']
conf_mat$overall['Accuracy']
accuracies = c()
indicators = c()
indicators <- c("uzzi_ref","uzzi_mesh","lee_ref","lee_mesh","foster_ref","foster_mesh","wang_ref","wang_mesh","shibayama_abstract","shibayama_title","author_intra_abstract","author_inter_abstract",
"author_intra_title", "author_inter_title")
df <- data.frame(indicators, accuracies)
indicators
accuracies
accuracies = c()
accuracies = append(accuracies, conf_mat$overall['Accuracy'])
for(i in indicators){
X_names <- append(c("nb_ref","year","nb_aut","journal_SJR"),c(i))
X_train = data.matrix(train[,X_names])
y_train = data.matrix(train[,"novel_f1000"])
X_test = data.matrix(test[,X_names])
y_test = data.matrix(test[,"novel_f1000"])
# convert the train and test data into xgboost matrix type.
xgboost_train = xgb.DMatrix(data=X_train, label=y_train)
xgboost_test = xgb.DMatrix(data=X_test, label=y_test)
model <- xgboost(data = xgboost_train,                    # the data
max.depth=3,                        # max depth
nrounds=50)                              # max number of boosting iterations
summary(model)
pred_test = predict(model, xgboost_test)
pred_test
pred_test[(pred_test>=0.75)] = 1
pred_test[(pred_test<0.75)] = 0
conf_mat = confusionMatrix(as.factor(y_test), as.factor(pred_test))
accuracies = append(accuracies, conf_mat$overall['Accuracy'])
}
accuracies = c()
for(i in indicators){
X_names <- append(c("nb_ref","year","nb_aut","journal_SJR"),c(i))
X_train = data.matrix(train[,X_names])
y_train = data.matrix(train[,"novel_f1000"])
X_test = data.matrix(test[,X_names])
y_test = data.matrix(test[,"novel_f1000"])
# convert the train and test data into xgboost matrix type.
xgboost_train = xgb.DMatrix(data=X_train, label=y_train)
xgboost_test = xgb.DMatrix(data=X_test, label=y_test)
model <- xgboost(data = xgboost_train,                    # the data
max.depth=3,                        # max depth
nrounds=50)                              # max number of boosting iterations
summary(model)
pred_test = predict(model, xgboost_test)
pred_test
pred_test[(pred_test>=0.75)] = 1
pred_test[(pred_test<0.75)] = 0
conf_mat = confusionMatrix(as.factor(y_test), as.factor(pred_test))
accuracies = append(accuracies, conf_mat$overall['Accuracy'])
}
df <- data.frame(indicators, accuracies)
df
conf_mat
novelty_cat
parts = createDataPartition(df_f1000$novel_f1000, p = 0.8, list = F)
train = df_f1000[parts, ]
test = df_f1000[-parts, ]
accuracies = c()
for(i in indicators){
X_names <- append(c("nb_ref","year","nb_aut","journal_SJR"),c(i))
X_train = data.matrix(train[,X_names])
y_train = data.matrix(train[,"novel_f1000"])
X_test = data.matrix(test[,X_names])
y_test = data.matrix(test[,"novel_f1000"])
# convert the train and test data into xgboost matrix type.
xgboost_train = xgb.DMatrix(data=X_train, label=y_train)
xgboost_test = xgb.DMatrix(data=X_test, label=y_test)
model <- xgboost(data = xgboost_train,                    # the data
max.depth=3,                        # max depth
nrounds=50)                              # max number of boosting iterations
summary(model)
pred_test = predict(model, xgboost_test)
pred_test
pred_test[(pred_test>=0.75)] = 1
pred_test[(pred_test<0.75)] = 0
conf_mat = confusionMatrix(as.factor(y_test), as.factor(pred_test))
#accuracies = append(accuracies, conf_mat$overall['Accuracy'])
#precision <- conf_mat$byClass['Pos Pred Value']
#recall <- conf_mat$byClass['Sensitivity']
accuracies = append(accuracies, conf_mat$byClass['Balanced Accuracy'] )
}
df <- data.frame(indicators, accuracies)
df
df["novel_f1000"] = accuracies
df
novelty_cat[0]
novelty_cat
df_f1000$categories
main_category
View(df_f1000)
str_replace_all(unique(df_f1000$main_category), c(" " = "_"  ))
f1000_cat <- str_replace_all(unique(df_f1000$main_category), c(" " = "_"  ))
cat = f1000_cat[1]
df[cat] = accuracies
df <- data.frame(indicators)
for(cat in f1000_cat){
accuracies = c()
for(i in indicators){
X_names <- append(c("nb_ref","year","nb_aut","journal_SJR"),c(i))
X_train = data.matrix(train[,X_names])
y_train = data.matrix(train[,"novel_f1000"])
X_test = data.matrix(test[,X_names])
y_test = data.matrix(test[,"novel_f1000"])
# convert the train and test data into xgboost matrix type.
xgboost_train = xgb.DMatrix(data=X_train, label=y_train)
xgboost_test = xgb.DMatrix(data=X_test, label=y_test)
model <- xgboost(data = xgboost_train,                    # the data
max.depth=3,                        # max depth
nrounds=50)                              # max number of boosting iterations
summary(model)
pred_test = predict(model, xgboost_test)
pred_test
pred_test[(pred_test>=0.75)] = 1
pred_test[(pred_test<0.75)] = 0
conf_mat = confusionMatrix(as.factor(y_test), as.factor(pred_test))
#accuracies = append(accuracies, conf_mat$overall['Accuracy'])
#precision <- conf_mat$byClass['Pos Pred Value']
#recall <- conf_mat$byClass['Sensitivity']
accuracies = append(accuracies, conf_mat$byClass['Balanced Accuracy'] )
df[cat] = accuracies
}
}
df
cat
df <- data.frame(indicators)
for(cat in f1000_cat){
accuracies = c()
for(i in indicators){
X_names <- append(c("nb_ref","year","nb_aut","journal_SJR"),c(i))
X_train = data.matrix(train[,X_names])
y_train = data.matrix(train[,"novel_f1000"])
X_test = data.matrix(test[,X_names])
y_test = data.matrix(test[,"novel_f1000"])
# convert the train and test data into xgboost matrix type.
xgboost_train = xgb.DMatrix(data=X_train, label=y_train)
xgboost_test = xgb.DMatrix(data=X_test, label=y_test)
model <- xgboost(data = xgboost_train,                    # the data
max.depth=3,                        # max depth
nrounds=50)                              # max number of boosting iterations
summary(model)
pred_test = predict(model, xgboost_test)
pred_test
pred_test[(pred_test>=0.75)] = 1
pred_test[(pred_test<0.75)] = 0
conf_mat = confusionMatrix(as.factor(y_test), as.factor(pred_test))
#accuracies = append(accuracies, conf_mat$overall['Accuracy'])
#precision <- conf_mat$byClass['Pos Pred Value']
#recall <- conf_mat$byClass['Sensitivity']
accuracies = append(accuracies, conf_mat$byClass['Balanced Accuracy'] )
}
df[cat] = accuracies
}
df
df <- data.frame(indicators)
for(cat in f1000_cat){
accuracies = c()
for(i in indicators){
X_names <- append(c("nb_ref","year","nb_aut","journal_SJR"),c(i))
X_train = data.matrix(train[,X_names])
y_train = data.matrix(train[,cat])
X_test = data.matrix(test[,X_names])
y_test = data.matrix(test[,cat])
# convert the train and test data into xgboost matrix type.
xgboost_train = xgb.DMatrix(data=X_train, label=y_train)
xgboost_test = xgb.DMatrix(data=X_test, label=y_test)
model <- xgboost(data = xgboost_train,                    # the data
max.depth=3,                        # max depth
nrounds=50)                              # max number of boosting iterations
summary(model)
pred_test = predict(model, xgboost_test)
pred_test
pred_test[(pred_test>=0.75)] = 1
pred_test[(pred_test<0.75)] = 0
conf_mat = confusionMatrix(as.factor(y_test), as.factor(pred_test))
#accuracies = append(accuracies, conf_mat$overall['Accuracy'])
#precision <- conf_mat$byClass['Pos Pred Value']
#recall <- conf_mat$byClass['Sensitivity']
accuracies = append(accuracies, conf_mat$byClass['Balanced Accuracy'] )
}
df[cat] = accuracies
}
df
parts = createDataPartition(df_f1000[cat], p = 0.8, list = F)
df_f1000[cat]
parts = createDataPartition(df_f1000[cat], p = 0.8, list = F)
df_f1000[,cat]
parts = createDataPartition(df_f1000[,cat], p = 0.8, list = F)
parts = createDataPartition(df_f1000$novel_f1000, p = 0.8, list = F)
df_f1000$novel_f1000
df_f1000$paste(cat)
paste(cat)
parts = createDataPartition(df_f1000[,"New_Finding"], p = 0.8, list = F)
df_f1000[,"New_Finding"]
parts = createDataPartition(as.matrix(df_f1000[,"New_Finding"]), p = 0.8, list = F)
train = df_f1000[parts, ]
test = df_f1000[-parts, ]
parts = createDataPartition(as.matrix(df_f1000[,cat]), p = 0.8, list = F)
train = df_f1000[parts, ]
test = df_f1000[-parts, ]
X_names <- append(c("nb_ref","year","nb_aut","journal_SJR"),c(i))
df <- data.frame(indicators)
for(cat in f1000_cat){
accuracies = c()
for(i in indicators){
parts = createDataPartition(as.matrix(df_f1000[,cat]), p = 0.8, list = F)
train = df_f1000[parts, ]
test = df_f1000[-parts, ]
X_names <- append(c("nb_ref","year","nb_aut","journal_SJR"),c(i))
X_train = data.matrix(train[,X_names])
y_train = data.matrix(train[,cat])
X_test = data.matrix(test[,X_names])
y_test = data.matrix(test[,cat])
# convert the train and test data into xgboost matrix type.
xgboost_train = xgb.DMatrix(data=X_train, label=y_train)
xgboost_test = xgb.DMatrix(data=X_test, label=y_test)
model <- xgboost(data = xgboost_train,                    # the data
max.depth=3,                        # max depth
nrounds=50)                              # max number of boosting iterations
summary(model)
pred_test = predict(model, xgboost_test)
pred_test
pred_test[(pred_test>=0.75)] = 1
pred_test[(pred_test<0.75)] = 0
conf_mat = confusionMatrix(as.factor(y_test), as.factor(pred_test))
#accuracies = append(accuracies, conf_mat$overall['Accuracy'])
#precision <- conf_mat$byClass['Pos Pred Value']
#recall <- conf_mat$byClass['Sensitivity']
accuracies = append(accuracies, conf_mat$byClass['Balanced Accuracy'] )
}
df[cat] = accuracies
}
df
y_test
df_f1000[,cat]
summary(df_f1000[,cat])
ifelse(main_category > 1, 1, 0)
ifelse(df_f1000[paste(i)] > 1, 1, 0)
df_f1000[paste(i,"_binary")] <- ifelse(df_f1000[paste(i)] > 1, 1, 0)
for (i in unique(df_f1000$main_category)){
df_f1000[paste(i)] <- lengths(regmatches(df_f1000$categories, gregexpr(i,df_f1000$categories)))
df_f1000[paste(i,"_binary")] <- ifelse(df_f1000[paste(i)] > 1, 1, 0)
}
f1000_cat = c()
f1000_cat_binary = c()
for (i in unique(df_f1000$main_category)){
df_f1000[paste(i)] <- lengths(regmatches(df_f1000$categories, gregexpr(i,df_f1000$categories)))
df_f1000[paste(i,"_binary")] <- ifelse(df_f1000[paste(i)] > 1, 1, 0)
f1000_cat <- append(f1000_cat,str_replace_all(i, c(" " = "_"  )))
f1000_cat_binary <- append(f1000_cat,str_replace_all(paste(i,"_binary"), c(" " = "_"  )))
}
f1000_cat
f1000_cat_binary
f1000_cat = c()
f1000_cat_binary = c()
for (i in unique(df_f1000$main_category)){
df_f1000[paste(i)] <- lengths(regmatches(df_f1000$categories, gregexpr(i,df_f1000$categories)))
df_f1000[paste(i,"_binary")] <- ifelse(df_f1000[paste(i)] > 1, 1, 0)
f1000_cat <- append(f1000_cat,str_replace_all(i, c(" " = "_"  )))
f1000_cat_binary <- append(f1000_cat_binary,str_replace_all(paste(i,"_binary"), c(" " = "_"  )))
}
f1000_cat_binary
